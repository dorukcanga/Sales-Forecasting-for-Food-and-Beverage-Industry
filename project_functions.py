# -*- coding: utf-8 -*-
"""project_functions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HovJe7RU98E-Kzl-TGuiwtQJhfcCZUOr
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
import seaborn as sns
import warnings

from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import acf ,pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import arma_order_select_ic
from IPython.core.display import display, HTML, clear_output
from pandas.plotting import register_matplotlib_converters

class ExploratorySingle:

  target_column = None
  
  def __init__(self, dataframe):
    self.dataset = dataframe

  def filter_groupby(self, il = None, ilçe = None, UrunGrubu = None):
    self.dataset_2 = self.dataset.copy()
    self.il = None
    self.ilçe = None
    self.urungrubu = None

    self.il = il
    self.ilçe = ilçe
    self.urungrubu = UrunGrubu

    if il != None:
      self.dataset_2 = self.dataset_2[self.dataset_2['City'] == self.il]
    if ilçe != None:
      self.dataset_2 = self.dataset_2[self.dataset_2['District'] == self.ilçe]
    if UrunGrubu != None:
      self.dataset_2 = self.dataset_2[self.dataset_2['SKUGroup'] == self.urungrubu]

    self.dataset_2 = pd.DataFrame(self.dataset_2.groupby('MonthBegin')[self.target_column].sum())

  def reset_filter(self):
    self.dataset_2 = self.dataset.copy()
    self.il = None
    self.ilçe = None
    self.urungrubu = None

  @classmethod
  def set_target_column(cls, column):
    cls.target_column = column

  def sales_graph(self):
    register_matplotlib_converters()
    plt.figure(figsize=(15,5))
    plt.plot(self.dataset_2[self.target_column], c="red",label="Actual Values", linewidth =5)
    plt.plot(self.dataset_2[self.target_column].rolling(6).mean(),label="Rolling Mean",linestyle ="--")
    plt.plot(self.dataset_2[self.target_column].rolling(6).std(),label="Rolling Standard Dev",linestyle ="--")
    plt.title("Sales in Liters - {}/{}/{}".format(self.il, self.ilçe, self.urungrubu), fontsize=22)
    plt.xlim(self.dataset.index.min(),"2019-06-01")
    plt.ylabel("Liters",fontsize=15)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

  def monthly_boxplot(self):
    self.dataset_2['Month'] = self.dataset_2.index.month
    self.dataset_2['Year'] = self.dataset_2.index.year
    self.dataset_2.pivot_table(index='Year',columns='Month',values=[self.target_column]).plot(kind='box')
    plt.show()

  def sd_fn(self): 
      decomposition = seasonal_decompose(self.dataset_2[self.target_column],model='additive', filt=None,
                                        freq=None, two_sided=True, extrapolate_trend=1)

      self.trend_org = decomposition.trend
      self.seasonal_org = decomposition.seasonal
      self.residual_org = decomposition.resid

      plt.figure(figsize=(16,10))
      plt.subplot(221)
      plt.plot(self.dataset_2[self.target_column], label='Original',c="r")
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.subplot(222)
      plt.plot(self.trend_org, label='Trend')
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.subplot(223)
      plt.plot(self.seasonal_org,label='Seasonality',c="green")
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.subplot(224)
      plt.plot(self.residual_org, label='Residuals',c="orange")
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.tight_layout()
      
      return self.trend_org,self.seasonal_org,self.residual_org

  def sd_fn_resid(self):
      decomposition = seasonal_decompose(self.residual_org,model='additive', filt=None,
                                        freq=None, two_sided=True, extrapolate_trend=1)

      self.trend_res = decomposition.trend
      self.seasonal_res = decomposition.seasonal
      self.residual_res = decomposition.resid

      plt.figure(figsize=(16,10))
      plt.subplot(221)
      plt.plot(self.residual_org, label='Original',c="r")
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.subplot(222)
      plt.plot(self.trend_res, label='Trend')
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.subplot(223)
      plt.plot(self.seasonal_res,label='Seasonality',c="green")
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.subplot(224)
      plt.plot(self.residual_res, label='Residuals',c="orange")
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.tight_layout()
      
      return self.trend_res,self.seasonal_res,self.residual_res

  def adf_fn(self, difference = None):
    if difference == None or difference == 0:
      adf_test_result = adfuller(self.dataset_2[self.target_column].values.ravel())
      print('Original Serie')
    else:
      adf_test_result = adfuller(self.dataset_2[self.target_column].diff(difference)[difference:].values.ravel())
      print('Difference -', str(difference))
    print('ADF Statistic: %f' % adf_test_result[0])
    print('p-value: %f' % adf_test_result[1])
    print('Critical Values:')
    for key, value in adf_test_result[4].items():
      print('\t%s: %.3f' % (key, value))

  def acf_pacf_plots(self, lag, alfa, difference = None):
    if difference == None or difference == 0:
      plot_acf(self.dataset_2[self.target_column], lags=lag, alpha= alfa)
      plt.show()
      plot_pacf(self.dataset_2[self.target_column], lags=lag, alpha= alfa)
      plt.show()
    else:
      plot_acf(self.dataset_2[self.target_column].diff(difference)[difference:], lags=lag, alpha= alfa)
      plt.show()
      plot_pacf(self.dataset_2[self.target_column].diff(difference)[difference:], lags=lag, alpha= alfa)
      plt.show()

  def monthly_variation(self):
    p1 = pd.pivot_table(data=self.dataset_2[(self.dataset_2["Year"]<=2018)],index = "Month",columns = "Year",
                        values = self.target_column, aggfunc="sum", margins = True)
    p2 = pd.DataFrame(index=p1.index,columns = p1.columns)
    for j in p2.columns:
        for i in p2.index:
            p2.loc[i,j]=p1.loc[i,j]/p1.loc["All",j]*100
    p2 = p2.astype("float")

    plt.figure(figsize=(9,6))
    sns.heatmap(p2.iloc[0:12,:], annot=True,vmin=0, vmax=13,cmap = "Reds")
    plt.show()

class ExploratoryMultiple:

  target_column = None
  iter_column = None
  
  def __init__(self, dataframe):
    self.dataset = dataframe

  def dataframe_filter(self, il = None, ilçe = None, UrunGrubu = None):
    self.dataset_2 = self.dataset.copy()
    self.il = None
    self.ilçe = None
    self.urungrubu = None

    self.il = il
    self.ilçe = ilçe
    self.urungrubu = UrunGrubu

    if il != None:
      self.dataset_2 = self.dataset_2[self.dataset_2['City'] == self.il]
    if ilçe != None:
      self.dataset_2 = self.dataset_2[self.dataset_2['District'] == self.ilçe]
    if UrunGrubu != None:
      self.dataset_2 = self.dataset_2[self.dataset_2['SKUGroup'] == self.urungrubu]

  @classmethod
  def set_target_column(cls, column):
    cls.target_column = column

  @classmethod
  def set_iteration_column(cls, column):
    cls.iter_column = column
  
  def all_sales_graphs(self):
    for value in self.dataset_2[self.iter_column].unique():
      self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
      register_matplotlib_converters()
      plt.figure(figsize=(15,5))
      plt.plot(self.dataset_3[self.target_column], c="red",label="Actual Values", linewidth =5)
      plt.plot(self.dataset_3[self.target_column].rolling(6).mean(),label="Rolling Mean",linestyle ="--")
      plt.plot(self.dataset_3[self.target_column].rolling(6).std(),label="Rolling Standard Dev",linestyle ="--")
      plt.title("Sales in Liters - {}/{}/{} - Target Column:{}".format(self.il, self.ilçe, self.urungrubu, value), fontsize=22)
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.ylabel("Liters",fontsize=15)
      plt.legend()
      plt.grid(True)
      plt.tight_layout()
      plt.show()

  def all_monthly_boxplots(self):
    for value in self.dataset_2[self.iter_column].unique():
      self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
      self.dataset_3['Month'] = self.dataset_3.index.month
      self.dataset_3['Year'] = self.dataset_3.index.year
      self.dataset_3.pivot_table(index='Year',columns='Month',values=self.target_column).plot(kind='box')
      plt.title("Monthly Sales - Target Column:{}".format(value))
      plt.show()

  def all_sd_plots(self):
    for value in self.dataset_2[self.iter_column].unique():
      self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
      decomposition = seasonal_decompose(self.dataset_3[self.target_column],model='additive', filt=None,
                                        freq=None, two_sided=True, extrapolate_trend=1)

      self.trend_org = decomposition.trend
      self.seasonal_org = decomposition.seasonal
      self.residual_org = decomposition.resid

      plt.figure(figsize=(16,10))
      plt.subplot(221)
      plt.plot(self.dataset_3[self.target_column], label='Original',c="r")
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.title("Original Series - Target Column:{}".format(value))
      plt.subplot(222)
      plt.plot(self.trend_org, label='Trend')
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.title("Trend - Target Column:{}".format(value))
      plt.subplot(223)
      plt.plot(self.seasonal_org,label='Seasonality',c="green")
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.title("Seasonality - Target Column:{}".format(value))
      plt.subplot(224)
      plt.plot(self.residual_org, label='Residuals',c="orange")
      plt.xlim(self.dataset.index.min(),"2019-06-01")
      plt.legend(loc='best',fontsize=15)
      plt.title("Residuals - Target Column:{}".format(value))
      plt.tight_layout()

  def all_adf_print(self, difference = None):
    if difference == None or difference == 0:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        adf_test_result = adfuller(self.dataset_3[self.target_column].values.ravel())
        print('Original Serie - Target Column:{}'.format(value))
        print('ADF Statistic: %f' % adf_test_result[0])
        print('p-value: %f' % adf_test_result[1])
        print('Critical Values:')
        for key, value in adf_test_result[4].items():
            print('\t%s: %.3f' % (key, value))
    else:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        adf_test_result = adfuller(self.dataset_3[self.target_column].diff(difference)[difference:].values.ravel())
        print('Difference -', str(difference), '- Target Column:{}'.format(value))
        print('ADF Statistic: %f' % adf_test_result[0])
        print('p-value: %f' % adf_test_result[1])
        print('Critical Values:')
        for key, value in adf_test_result[4].items():
            print('\t%s: %.3f' % (key, value))

  def all_acf_pacf_plots(self, lag, alfa, difference = None):
    if difference == None or difference == 0:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        try:
          print('ACF & PACF Plots - Target Column:{}'.format(value))
          plot_acf(self.dataset_3[self.target_column], lags=lag, alpha= alfa)
          plot_pacf(self.dataset_3[self.target_column], lags=lag, alpha= alfa)
          plt.show()
        except:
          print('Error: Not enough data point - Target Column:{}'.format(value))
    else:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        try:
          print('ACF & PACF Plots - Target Column:{}'.format(value))
          plot_acf(self.dataset_3[self.target_column].diff(difference)[difference:], lags=lag, alpha= alfa)
          plot_pacf(self.dataset_3[self.target_column].diff(difference)[difference:], lags=lag, alpha= alfa)
          plt.show()
        except:
          print('Error: Not enough data point - Target Column:{}'.format(value))

  def all_adf_summary(self, difference = None):
    adf_results = pd.DataFrame(columns=[self.iter_column, 'ADF Statistic', 'p-value', '1%', '5%', '10%'])
    if difference == None or difference == 0:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        result = adfuller(self.dataset_3[self.target_column].values.ravel())
        result_dict = {self.iter_column : value, 'ADF Statistic' : result[0], 'p-value' : result[1], '1%' : result[4]['1%'], '5%' : result[4]['5%'], '10%' : result[4]['10%']}
        adf_results = adf_results.append([result_dict], ignore_index=True)
    else:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        result = adfuller(self.dataset_3[self.target_column].diff(difference)[difference:].values.ravel())
        result_dict = {self.iter_column : value, 'ADF Statistic' : result[0], 'p-value' : result[1], '1%' : result[4]['1%'], '5%' : result[4]['5%'], '10%' : result[4]['10%']}
        adf_results = adf_results.append([result_dict], ignore_index=True)

    print('ADF Test Results Summary:')
    print('Total number of targets:', self.dataset_2[self.iter_column].nunique())
    print('Number of targets with p-value smaller than 5%:', sum(adf_results['p-value'] < 0.05))
    print('Number of targets with ADF Statistic smaller than 1%:', sum(adf_results['ADF Statistic'] < adf_results['1%']))
    print('Number of targets with ADF Statistic between 1% - 5%:', sum((adf_results['ADF Statistic'] >= adf_results['1%']) & (adf_results['ADF Statistic'] < adf_results['5%'])))
    print('Number of targets with ADF Statistic between 5% - 10%:', sum((adf_results['ADF Statistic'] >= adf_results['5%']) & (adf_results['ADF Statistic'] < adf_results['10%'])))
    print('Number of targets with ADF Statistic larger than 10%:', sum(adf_results['ADF Statistic'] >= adf_results['10%']))
    return adf_results

  def acf_results(self, lag, alfa, difference = None):
    list_of_lag_lists = []
    if difference == None or difference == 0:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        try:
          result_list = acf(self.dataset_3[self.target_column], nlags=lag, alpha=alfa)[1]
          sign_lag_list = []
          for i in range(1, len(result_list)):
            if (result_list[i][0] < 0 and result_list[i][1] < 0) or (result_list[i][0] > 0 and result_list[i][1] > 0):
              sign_lag_list.append(i)
          list_of_lag_lists.append((value, sign_lag_list))
        except:
          list_of_lag_lists.append((value, ['Error']))
    else:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        try:
          result_list = acf(self.dataset_3[self.target_column].diff(difference)[difference:], nlags=lag, alpha=alfa)[1]
          sign_lag_list = []
          for i in range(1, len(result_list)):
            if (result_list[i][0] < 0 and result_list[i][1] < 0) or (result_list[i][0] > 0 and result_list[i][1] > 0):
              sign_lag_list.append(i)
          list_of_lag_lists.append((value, sign_lag_list))
        except:
          list_of_lag_lists.append((value, ['Error']))

    sign_lag_df = pd.DataFrame(list_of_lag_lists, columns=[self.iter_column, 'Significant Lags'])

    print('Total number of unique values in target column:', self.dataset_2[self.iter_column].nunique())
    print('Number of Errors:', sum(x.count('Error') for x in sign_lag_df['Significant Lags'].tolist()))
    for i in range(1,lag+1):
      count = sum(x.count(i) for x in sign_lag_df['Significant Lags'].tolist())
      print('Number of times Lag -', i, 'is significant:', count)
    return sign_lag_df

  def pacf_results(self, lag, alfa, method, difference = None):
    list_of_lag_lists = []
    if difference == None or difference == 0:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        try:
          result_list = pacf(self.dataset_3[self.target_column], nlags=lag, alpha=alfa, method=method)[1]
          sign_lag_list = []
          for i in range(1, len(result_list)):
            if (result_list[i][0] < 0 and result_list[i][1] < 0) or (result_list[i][0] > 0 and result_list[i][1] > 0):
              sign_lag_list.append(i)
          list_of_lag_lists.append((value, sign_lag_list))
        except:
          list_of_lag_lists.append((value, ['Error']))
    else:
      for value in self.dataset_2[self.iter_column].unique():
        self.dataset_3 = pd.DataFrame(self.dataset_2[self.dataset_2[self.iter_column] == value].groupby('MonthBegin')[self.target_column].sum())
        try:
          result_list = pacf(self.dataset_3[self.target_column].diff(difference)[difference:], nlags=lag, alpha=alfa, method=method)[1]
          sign_lag_list = []
          for i in range(1, len(result_list)):
            if (result_list[i][0] < 0 and result_list[i][1] < 0) or (result_list[i][0] > 0 and result_list[i][1] > 0):
              sign_lag_list.append(i)
          list_of_lag_lists.append((value, sign_lag_list))
        except:
          list_of_lag_lists.append((value, ['Error']))

    sign_lag_df = pd.DataFrame(list_of_lag_lists, columns=[self.iter_column, 'Significant Lags'])

    print('Total number of unique values in target column:', self.dataset_2[self.iter_column].nunique())
    print('Number of Errors:', sum(x.count('Error') for x in sign_lag_df['Significant Lags'].tolist()))
    for i in range(1,lag+1):
      count = sum(x.count(i) for x in sign_lag_df['Significant Lags'].tolist())
      print('Number of times Lag -', i, 'is significant:', count)
    return sign_lag_df

  def all_monthly_variation(self):
    for x in self.dataset_2[self.iter_column].unique():
      self.sales_data_group = self.dataset_2[self.dataset_2[self.iter_column] == x]
      p1 = pd.pivot_table(data=self.sales_data_group[(self.sales_data_group["Year"]<=2018)],index = "Month",columns = "Year",
                          values = self.target_column, aggfunc="sum", margins = True)
      p2 = pd.DataFrame(index=p1.index,columns = p1.columns)
      for j in p2.columns:
          for i in p2.index:
              p2.loc[i,j]=p1.loc[i,j]/p1.loc["All",j]*100
      p2 = p2.astype("float")

      plt.figure(figsize=(9,6))
      plt.title(x)
      sns.heatmap(p2.iloc[0:12,:], annot=True,vmin=0, vmax=13,cmap = "Reds")
      plt.show()

class BaselinePrediction:

  target_column = None
  iter_column = None

  def __init__(self, dataframe):
    self.dataset = dataframe

  def dataframe_filter(self, il = None, ilçe = None, UrunGrubu = None):
    self.dataset_2 = self.dataset.copy()
    self.il = None
    self.ilçe = None
    self.urungrubu = None

    self.il = il
    self.ilçe = ilçe
    self.urungrubu = UrunGrubu

    if il != None:
      self.dataset_2 = self.dataset_2[self.dataset_2['City'] == self.il]
    if ilçe != None:
      self.dataset_2 = self.dataset_2[self.dataset_2['District'] == self.ilçe]
    if UrunGrubu != None:
      self.dataset_2 = self.dataset_2[self.dataset_2['SKUGroup'] == self.urungrubu]

  @classmethod
  def set_target_column(cls, column):
    cls.target_column = column

  @classmethod
  def set_iteration_column(cls, column):
    cls.iter_column = column

  def groupby_fn(self):
    self.sales_data_group = pd.DataFrame(self.dataset_2.groupby(['MonthBegin',self.iter_column])[self.target_column].sum()).reset_index()
    return self.sales_data_group

  def shift_mape_dictionary(self, shift_number = 1, test_months = 6):
    self.month_df = pd.DataFrame(self.dataset.index.unique(), columns=['MonthBegin'])
    
    test_mape_dict = {}
    train_mape_dict = {}
    for i in self.sales_data_group[self.iter_column].unique():
      self.bayi_df = self.sales_data_group[self.sales_data_group[self.iter_column] == i][['MonthBegin', self.target_column]]
      self.bayi_df = self.month_df.merge(self.bayi_df, on='MonthBegin', how='left').fillna(0)

      self.error_df_test = pd.concat([self.bayi_df[self.target_column][-test_months:],self.bayi_df[self.target_column].shift(shift_number)[-test_months:]], axis=1)
      self.error_df_test.columns=["y_true","y_pred"]
      self.error_df_test = self.error_df_test[(self.error_df_test.y_true.notna()) & (self.error_df_test.y_true > 1)]
      if len(self.error_df_test) != 0:
        mape = round((np.abs(self.error_df_test.y_true - self.error_df_test.y_pred)/self.error_df_test.y_true).mean(), 4)
        test_mape_dict[i] = mape
      else:
        test_mape_dict[i] = np.nan

      self.error_df_train = pd.concat([self.bayi_df[self.target_column][:-test_months],self.bayi_df[self.target_column].shift(shift_number)[:-test_months]], axis=1)
      self.error_df_train.columns=["y_true","y_pred"]
      self.error_df_train = self.error_df_train[(self.error_df_train.y_true.notna()) & (self.error_df_train.y_true > 1)]
      if len(self.error_df_train) != 0:
        mape = round((np.abs(self.error_df_train.y_true - self.error_df_train.y_pred)/self.error_df_train.y_true).mean(), 4)
        train_mape_dict[i] = mape
      else:
        train_mape_dict[i] = np.nan

    return train_mape_dict, test_mape_dict

  def mean_mape_dictionary(self, rolling_number = 1, test_months = 6):
    self.month_df = pd.DataFrame(self.dataset.index.unique(), columns=['MonthBegin'])
    
    test_mape_dict = {}
    train_mape_dict = {}
    for i in self.sales_data_group[self.iter_column].unique():
      self.bayi_df = self.sales_data_group[self.sales_data_group[self.iter_column] == i][['MonthBegin', self.target_column]]
      self.bayi_df = self.month_df.merge(self.bayi_df, on='MonthBegin', how='left').fillna(0)

      self.error_df_test = pd.concat([self.bayi_df[self.target_column][-test_months:],self.bayi_df[self.target_column].shift().rolling(rolling_number).mean()[-test_months:]], axis=1)
      self.error_df_test.columns=["y_true","y_pred"]
      self.error_df_test = self.error_df_test[(self.error_df_test.y_true.notna()) & (self.error_df_test.y_true > 1)]
      if len(self.error_df_test) != 0:
        mape = round((np.abs(self.error_df_test.y_true - self.error_df_test.y_pred)/self.error_df_test.y_true).mean(), 4)
        test_mape_dict[i] = mape
      else:
        test_mape_dict[i] = np.nan

      self.error_df_train = pd.concat([self.bayi_df[self.target_column][:-test_months],self.bayi_df[self.target_column].shift().rolling(rolling_number).mean()[:-test_months]], axis=1)
      self.error_df_train.columns=["y_true","y_pred"]
      self.error_df_train = self.error_df_train[(self.error_df_train.y_true.notna()) & (self.error_df_train.y_true > 1)]
      if len(self.error_df_train) != 0:
        mape = round((np.abs(self.error_df_train.y_true - self.error_df_train.y_pred)/self.error_df_train.y_true).mean(), 4)
        train_mape_dict[i] = mape
      else:
        train_mape_dict[i] = np.nan

    return train_mape_dict, test_mape_dict


  def shift_mae_dictionary(self, shift_number = 1, test_months = 6):
    self.month_df = pd.DataFrame(self.dataset.index.unique(), columns=['MonthBegin'])
    
    test_mae_dict = {}
    train_mae_dict = {}
    for i in self.sales_data_group[self.iter_column].unique():
      self.bayi_df = self.sales_data_group[self.sales_data_group[self.iter_column] == i][['MonthBegin', self.target_column]]
      self.bayi_df = self.month_df.merge(self.bayi_df, on='MonthBegin', how='left').fillna(0)

      self.error_df_test = pd.concat([self.bayi_df[self.target_column][-test_months:],self.bayi_df[self.target_column].shift(shift_number)[-test_months:]], axis=1)
      self.error_df_test.columns=["y_true","y_pred"]
      self.error_df_test = self.error_df_test[(self.error_df_test.y_true.notna()) & (self.error_df_test.y_true > 1)]
      if len(self.error_df_test) != 0:
        mae = round((np.abs(self.error_df_test.y_true - self.error_df_test.y_pred)).mean(), 4)
        test_mae_dict[i] = mae
      else:
        test_mae_dict[i] = np.nan

      self.error_df_train = pd.concat([self.bayi_df[self.target_column][:-test_months],self.bayi_df[self.target_column].shift(shift_number)[:-test_months]], axis=1)
      self.error_df_train.columns=["y_true","y_pred"]
      self.error_df_train = self.error_df_train[(self.error_df_train.y_true.notna()) & (self.error_df_train.y_true > 1)]
      if len(self.error_df_train) != 0:
        mae = round((np.abs(self.error_df_train.y_true - self.error_df_train.y_pred)).mean(), 4)
        train_mae_dict[i] = mae
      else:
        train_mae_dict[i] = np.nan

    return train_mae_dict, test_mae_dict

  def mean_mae_dictionary(self, rolling_number = 1, test_months = 6):
    self.month_df = pd.DataFrame(self.dataset.index.unique(), columns=['MonthBegin'])
    
    test_mae_dict = {}
    train_mae_dict = {}
    for i in self.sales_data_group[self.iter_column].unique():
      self.bayi_df = self.sales_data_group[self.sales_data_group[self.iter_column] == i][['MonthBegin', self.target_column]]
      self.bayi_df = self.month_df.merge(self.bayi_df, on='MonthBegin', how='left').fillna(0)

      self.error_df_test = pd.concat([self.bayi_df[self.target_column][-test_months:],self.bayi_df[self.target_column].shift().rolling(rolling_number).mean()[-test_months:]], axis=1)
      self.error_df_test.columns=["y_true","y_pred"]
      self.error_df_test = self.error_df_test[(self.error_df_test.y_true.notna()) & (self.error_df_test.y_true > 1)]
      if len(self.error_df_test) != 0:
        mae = round((np.abs(self.error_df_test.y_true - self.error_df_test.y_pred)).mean(), 4)
        test_mae_dict[i] = mae
      else:
        test_mae_dict[i] = np.nan

      self.error_df_train = pd.concat([self.bayi_df[self.target_column][:-test_months],self.bayi_df[self.target_column].shift().rolling(rolling_number).mean()[:-test_months]], axis=1)
      self.error_df_train.columns=["y_true","y_pred"]
      self.error_df_train = self.error_df_train[(self.error_df_train.y_true.notna()) & (self.error_df_train.y_true > 1)]
      if len(self.error_df_train) != 0:
        mae = round((np.abs(self.error_df_train.y_true - self.error_df_train.y_pred)).mean(), 4)
        train_mae_dict[i] = mae
      else:
        train_mae_dict[i] = np.nan

    return train_mae_dict, test_mae_dict